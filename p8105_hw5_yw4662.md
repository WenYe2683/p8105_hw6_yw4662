p8105-hw6-yw4662
================

## Problem 1

``` r
# Import homicide data from Washington Post GitHub
homicide_raw <- read_csv(
  "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"
)
```

    ## Rows: 52179 Columns: 12
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (9): uid, victim_last, victim_first, victim_race, victim_age, victim_sex...
    ## dbl (3): reported_date, lat, lon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
# Clean and create city_state + solved indicator
homicide_clean <- homicide_raw %>%
  mutate(
    city_state = str_c(city, ", ", state),
    solved = disposition == "Closed by arrest"
  )%>%
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", 
                      "Kansas City, MO", "Tulsa, AL")
  ) %>%
  filter(victim_race %in% c("White", "Black")) %>%
  mutate(
    victim_age = as.numeric(victim_age),
    victim_sex = factor(victim_sex),
    victim_race = factor(victim_race)
  )
```

### Baltimore Logistic Regression and Adjusted OR (Male VS Female)

``` r
baltimore_df <- homicide_clean %>%
  filter(city_state == "Baltimore, MD")

baltimore_fit <- glm(
  solved ~ victim_age + victim_sex + victim_race,
  data = baltimore_df,
  family = binomial()
)

baltimore_OR <- baltimore_fit %>%
  tidy(conf.int = TRUE, exponentiate = TRUE) %>%
  filter(term == "victim_sexMale") %>%
  select(term, estimate, conf.low, conf.high)

baltimore_OR
```

    ## # A tibble: 1 × 4
    ##   term           estimate conf.low conf.high
    ##   <chr>             <dbl>    <dbl>     <dbl>
    ## 1 victim_sexMale    0.426    0.324     0.558

### Logistic Regression for Each City and OR (Male VS Female)

``` r
city_ORs <- homicide_clean %>%
  group_by(city_state) %>%
  nest() %>%
  mutate(
    fit = map(
      data,
      ~ glm(solved ~ victim_age + victim_sex + victim_race,
            data = .x,
            family = binomial())
    ),
    tidied = map(
      fit,
      ~ tidy(.x, conf.int = TRUE, exponentiate = TRUE)
    )
  ) %>%
  unnest(tidied) %>%
  filter(term == "victim_sexMale") %>%
  select(city_state, estimate, conf.low, conf.high)
```

    ## Warning: There were 43 warnings in `mutate()`.
    ## The first warning was:
    ## ℹ In argument: `tidied = map(fit, ~tidy(.x, conf.int = TRUE, exponentiate =
    ##   TRUE))`.
    ## ℹ In group 1: `city_state = "Albuquerque, NM"`.
    ## Caused by warning:
    ## ! glm.fit: fitted probabilities numerically 0 or 1 occurred
    ## ℹ Run `dplyr::last_dplyr_warnings()` to see the 42 remaining warnings.

``` r
city_ORs
```

    ## # A tibble: 47 × 4
    ## # Groups:   city_state [47]
    ##    city_state      estimate conf.low conf.high
    ##    <chr>              <dbl>    <dbl>     <dbl>
    ##  1 Albuquerque, NM    1.77     0.825     3.76 
    ##  2 Atlanta, GA        1.00     0.680     1.46 
    ##  3 Baltimore, MD      0.426    0.324     0.558
    ##  4 Baton Rouge, LA    0.381    0.204     0.684
    ##  5 Birmingham, AL     0.870    0.571     1.31 
    ##  6 Boston, MA         0.674    0.353     1.28 
    ##  7 Buffalo, NY        0.521    0.288     0.936
    ##  8 Charlotte, NC      0.884    0.551     1.39 
    ##  9 Chicago, IL        0.410    0.336     0.501
    ## 10 Cincinnati, OH     0.400    0.231     0.667
    ## # ℹ 37 more rows

### Plot of Adjusted ORs by City

``` r
city_ORs %>%
  ggplot(aes(x = estimate, y = fct_reorder(city_state, estimate))) +
  geom_point(color = "#0057A8") +
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high), width = 0) +
  geom_vline(xintercept = 1, linetype = 2) +
  labs(
    title = "Adjusted odds ratios for solving homicides (Male vs Female)",
    x = "Adjusted OR (Male vs Female)",
    y = NULL
  )
```

![](p8105_hw5_yw4662_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

### Comment

1.  **Most cities have adjusted ORs near 1**: An OR of 1 means that
    homicides involving male victims and female victims are equally
    likely to be solved after adjusting for covariates. Most cities fall
    between 0.7 and 1.3, indicating little to no difference in solve
    rates by victim sex.

2.  **Cities with very wide confidence intervals**: Some cities have
    long error bars, indicating smaller sample sizes, high uncertainty
    in estimates, and limited ability to draw conclusions.

## Problem 2

``` r
data("weather_df")

weather_clean <- weather_df %>%
  filter(!is.na(tmax), !is.na(tmin), !is.na(prcp))
```

### Bootstrap Resamples and Fits

``` r
# Create 5000 bootstrap resamples
boot_straps <- weather_clean %>%
  bootstrap(n = 5000, id = "strap_id")

boot_results <- boot_straps %>%
  mutate(
    model = map(strap, ~ lm(tmax ~ tmin + prcp, data = .x)),
    glance = map(model, glance),
    tidy = map(model, tidy)
  )

# r^2
boot_r2 <- boot_results %>%
  unnest(glance) %>%
  select(strap_id, r.squared)

# beta1 / beta2
boot_beta_ratio <- boot_results %>%
  unnest(tidy) %>%
  select(strap_id, term, estimate) %>%
  filter(term %in% c("tmin", "prcp")) %>%
  pivot_wider(names_from = term, values_from = estimate) %>%
  mutate(beta_ratio = tmin / prcp) %>%
  select(strap_id, beta_ratio)

boot_summary <- boot_r2 %>%
  inner_join(boot_beta_ratio, by = "strap_id")

boot_summary
```

    ## # A tibble: 5,000 × 3
    ##    strap_id r.squared beta_ratio
    ##    <chr>        <dbl>      <dbl>
    ##  1 0001         0.936      -221.
    ##  2 0002         0.941      -172.
    ##  3 0003         0.939      -218.
    ##  4 0004         0.942      -170.
    ##  5 0005         0.939      -203.
    ##  6 0006         0.940      -198.
    ##  7 0007         0.944      -169.
    ##  8 0008         0.939      -195.
    ##  9 0009         0.940      -179.
    ## 10 0010         0.945      -228.
    ## # ℹ 4,990 more rows

### Distribution and 95% Bootstrap CIs

``` r
# r^2 distribution
p_r2 <- boot_summary %>%
  ggplot(aes(x = r.squared)) +
  geom_histogram(bins = 40, fill = "#0057A8", alpha = 0.7) +
  labs(
    title = "Bootstrap distribution of R-squared",
    x = expression(hat(r)^2),
    y = "Count"
  )

# beta-ratio distribution
p_ratio <- boot_summary %>%
  ggplot(aes(x = beta_ratio)) +
  geom_histogram(bins = 40, fill = "#E53935", alpha = 0.7) +
  labs(
    title = "Bootstrap distribution of beta1 / beta2",
    x = expression(hat(beta)[1] / hat(beta)[2]),
    y = "Count"
  )

p_r2
```

![](p8105_hw5_yw4662_files/figure-gfm/unnamed-chunk-7-1.png)<!-- -->

``` r
p_ratio
```

![](p8105_hw5_yw4662_files/figure-gfm/unnamed-chunk-7-2.png)<!-- -->

### Comment

1.  Bootstrap distribution of $R^2$: the model fits very consistently
    well, with minimal sampling variability in $R^2$
    - The model explains about 94% of the variance in the response
      variable across bootstrap samples
    - The tight distribution indicates the model’s explanatory power is
      very stable
    - Even if we refit the model on many resampled datasets, the $R^2$
      would remain almost unchanged
2.  Bootstrap distribution of $\frac{\beta_1}{\beta_2}$: the ratio is
    much less stable than $R^2$, showing that estimating the relative
    strength of the two predictors is much less stable than estimating
    the overall model fit
    - The ratio is consistently negative, meaning the two coefficients
      have opposite signs in essentially every bootstrap sample
    - The skewness suggests higher variability in one or both
      coefficients
    - The wide range of values indicates that $\beta_2$ may sometimes be
      small in magnitude, which creates instability in the ratio

``` r
# 95% bootstrap intervals
r2_ci <- boot_summary %>%
  summarise(
    q2.5  = quantile(r.squared, 0.025),
    q97.5 = quantile(r.squared, 0.975)
  )

ratio_ci <- boot_summary %>%
  summarise(
    q2.5  = quantile(beta_ratio, 0.025),
    q97.5 = quantile(beta_ratio, 0.975)
  )

r2_ci
```

    ## # A tibble: 1 × 2
    ##    q2.5 q97.5
    ##   <dbl> <dbl>
    ## 1 0.934 0.947

``` r
ratio_ci
```

    ## # A tibble: 1 × 2
    ##    q2.5 q97.5
    ##   <dbl> <dbl>
    ## 1 -278. -125.

## Problem 3

``` r
birth_raw <- read_csv("./data/birthweight.csv")
```

    ## Rows: 4342 Columns: 20
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (20): babysex, bhead, blength, bwt, delwt, fincome, frace, gaweeks, malf...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
birth_df <- birth_raw %>%
  mutate(
    babysex = factor(babysex, levels = c(1, 2),
                     labels = c("male", "female")),
    frace   = factor(frace),
    mrace   = factor(mrace),
    malform = factor(malform, levels = c(0, 1),
                     labels = c("absent", "present"))
  ) %>%
  # drop rows with missing values
  drop_na()
```

### Proposed Regression Model for Birthweight

Here I choose a reasonably rich model using clinical/biological
predictors:

- Baby’s head circumference and length (`bhead`, `blength`)
- Gestational age in weeks (`gaweeks`)
- Baby sex (`babysex`)
- Mother’s pre-pregnancy BMI and weight gain (`ppbmi`, `wtgain`)
- Smoking during pregnancy (`smoken`)

``` r
mod_main <- lm(
  bwt ~ babysex + bhead + blength + gaweeks +
    ppbmi + wtgain + smoken,
  data = birth_df
)

summary(mod_main)
```

    ## 
    ## Call:
    ## lm(formula = bwt ~ babysex + bhead + blength + gaweeks + ppbmi + 
    ##     wtgain + smoken, data = birth_df)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -1091.57  -187.52    -8.63   174.13  2566.93 
    ## 
    ## Coefficients:
    ##                 Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)   -6205.8684    99.7743 -62.199  < 2e-16 ***
    ## babysexfemale    32.4025     8.7512   3.703 0.000216 ***
    ## bhead           137.6129     3.5433  38.838  < 2e-16 ***
    ## blength          79.5299     2.0705  38.410  < 2e-16 ***
    ## gaweeks          13.5098     1.5040   8.983  < 2e-16 ***
    ## ppbmi             5.1251     1.3654   3.754 0.000177 ***
    ## wtgain            3.7204     0.4054   9.177  < 2e-16 ***
    ## smoken           -1.9977     0.5827  -3.428 0.000613 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 282.6 on 4334 degrees of freedom
    ## Multiple R-squared:  0.6961, Adjusted R-squared:  0.6956 
    ## F-statistic:  1418 on 7 and 4334 DF,  p-value: < 2.2e-16

### Residuals vs fitted values

``` r
birth_aug <- birth_df %>%
  add_predictions(mod_main) %>%
  add_residuals(mod_main)

birth_aug %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.4) +
  geom_hline(yintercept = 0, linetype = 2) +
  labs(
    title = "Residuals vs fitted values: main birthweight model",
    x = "Fitted birthweight",
    y = "Residuals"
  )
```

![](p8105_hw5_yw4662_files/figure-gfm/unnamed-chunk-12-1.png)<!-- -->

**Comment**

1.  Residual spread increases with fitted birthweight, suggesting
    heteroscedasticity
2.  The residuals are centered around zero, indicating that the model
    does not show obvious large-scale bias in prediction across the
    range of fitted values
3.  Presence of extreme outliers, which likely correspond to biological
    or measurement anomalies and may strongly influence the fit

### Comparison Models

1.  **Model 1**: length at birth + gestational age
2.  **Model 2**: head circumference, length, sex, and all interactions

``` r
mod1 <- lm(bwt ~ blength + gaweeks, data = birth_df)

mod2 <- lm(
  bwt ~ bhead * blength * babysex,
  data = birth_df
)
```

### Cross-validated Prediction Error

``` r
set.seed(2025)

cv_df <- crossv_mc(birth_df, n = 100)

cv_results <- cv_df %>%
  mutate(
    train = map(train, as_tibble),
    test  = map(test, as_tibble),

    fit_main = map(train, ~ lm(
      bwt ~ babysex + bhead + blength + gaweeks +
        ppbmi + wtgain + smoken,
      data = .x
    )),
    fit_mod1 = map(train, ~ lm(
      bwt ~ blength + gaweeks,
      data = .x
    )),
    fit_mod2 = map(train, ~ lm(
      bwt ~ bhead * blength * babysex,
      data = .x
    )),

    rmse_main = map2_dbl(fit_main, test, ~ {
      pred  <- predict(.x, newdata = .y)
      sqrt(mean((.y$bwt - pred)^2))
    }),
    rmse_mod1 = map2_dbl(fit_mod1, test, ~ {
      pred  <- predict(.x, newdata = .y)
      sqrt(mean((.y$bwt - pred)^2))
    }),
    rmse_mod2 = map2_dbl(fit_mod2, test, ~ {
      pred  <- predict(.x, newdata = .y)
      sqrt(mean((.y$bwt - pred)^2))
    })
  )

# Summarize and compare
cv_long <- cv_results %>%
  select(rmse_main, rmse_mod1, rmse_mod2) %>%
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse"
  ) %>%
  mutate(
    model = recode(
      model,
      rmse_main = "Main model",
      rmse_mod1 = "Model 1",
      rmse_mod2 = "Model 2"
    )
  )

cv_long %>%
  group_by(model) %>%
  summarise(
    mean_rmse = mean(rmse),
    sd_rmse   = sd(rmse),
    .groups = "drop"
  )
```

    ## # A tibble: 3 × 3
    ##   model      mean_rmse sd_rmse
    ##   <chr>          <dbl>   <dbl>
    ## 1 Main model      283.    9.68
    ## 2 Model 1         334.   14.9 
    ## 3 Model 2         289.   10.2

``` r
cv_long %>%
  ggplot(aes(x = model, y = rmse)) +
  geom_boxplot() +
  labs(
    title = "Cross-validated RMSE for birthweight models",
    x = NULL,
    y = "RMSE on test sets"
  ) +
  coord_flip()
```

![](p8105_hw5_yw4662_files/figure-gfm/unnamed-chunk-15-1.png)<!-- -->

**Comment**

1.  The main model performs best. The median RMSE for the main model is
    the lowest among the three, and its RMSE distribution is also tight,
    suggesting stable performance across folds. This indicates that
    including multiple predictors improves predictive accuracy.
2.  Model 2 performs similarly to the main model, and its variability is
    also modest, suggesting that the three-way interaction contributes
    useful information, but not enoughg to outperform the main model
3.  Model 1 performs the worst and has a much higher median RMSE and the
    widest spread, suggesting thaht using only two predictors results in
    substantial information loss
