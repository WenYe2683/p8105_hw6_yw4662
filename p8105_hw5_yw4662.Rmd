---
title: "p8105-hw6-yw4662"
output: github_document
---
```{r setup, include = FALSE}
library(tidyverse)
library(broom)
library(modelr)
library(p8105.datasets)

set.seed(2025)
theme_set(theme_minimal(base_size = 14))
```

## Problem 1

```{r, warning = FALSE}
# Import homicide data from Washington Post GitHub
homicide_raw <- read_csv(
  "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"
)

# Clean and create city_state + solved indicator
homicide_clean <- homicide_raw %>%
  mutate(
    city_state = str_c(city, ", ", state),
    solved = disposition == "Closed by arrest"
  )%>%
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", 
                      "Kansas City, MO", "Tulsa, AL")
  ) %>%
  filter(victim_race %in% c("White", "Black")) %>%
  mutate(
    victim_age = as.numeric(victim_age),
    victim_sex = factor(victim_sex),
    victim_race = factor(victim_race)
  )

```

### Baltimore Logistic Regression and Adjusted OR (Male VS Female) 

```{r}
baltimore_df <- homicide_clean %>%
  filter(city_state == "Baltimore, MD")

baltimore_fit <- glm(
  solved ~ victim_age + victim_sex + victim_race,
  data = baltimore_df,
  family = binomial()
)

baltimore_OR <- baltimore_fit %>%
  tidy(conf.int = TRUE, exponentiate = TRUE) %>%
  filter(term == "victim_sexMale") %>%
  select(term, estimate, conf.low, conf.high)

baltimore_OR
```

### Logistic Regression for Each City and OR (Male VS Female)

```{r}
city_ORs <- homicide_clean %>%
  group_by(city_state) %>%
  nest() %>%
  mutate(
    fit = map(
      data,
      ~ glm(solved ~ victim_age + victim_sex + victim_race,
            data = .x,
            family = binomial())
    ),
    tidied = map(
      fit,
      ~ tidy(.x, conf.int = TRUE, exponentiate = TRUE)
    )
  ) %>%
  unnest(tidied) %>%
  filter(term == "victim_sexMale") %>%
  select(city_state, estimate, conf.low, conf.high)

city_ORs
```

### Plot of Adjusted ORs by City

```{r fig.width = 10, fig.height = 8}
city_ORs %>%
  ggplot(aes(x = estimate, y = fct_reorder(city_state, estimate))) +
  geom_point(color = "#0057A8") +
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high), width = 0) +
  geom_vline(xintercept = 1, linetype = 2) +
  labs(
    title = "Adjusted odds ratios for solving homicides (Male vs Female)",
    x = "Adjusted OR (Male vs Female)",
    y = NULL
  )
```

### Comment
1. **Most cities have adjusted ORs near 1**: An OR of 1 means that homicides involving male victims and female victims are equally likely to be solved after adjusting for covariates. Most cities fall between 0.7 and 1.3, indicating little to no difference in solve rates by victim sex. 

2. **Cities with very wide confidence intervals**: Some cities have long error bars, indicating smaller sample sizes, high uncertainty in estimates, and limited ability to draw conclusions. 

## Problem 2

```{r}
data("weather_df")

weather_clean <- weather_df %>%
  filter(!is.na(tmax), !is.na(tmin), !is.na(prcp))
```

### Bootstrap Resamples and Fits

```{r}
# Create 5000 bootstrap resamples
boot_straps <- weather_clean %>%
  bootstrap(n = 5000, id = "strap_id")

boot_results <- boot_straps %>%
  mutate(
    model = map(strap, ~ lm(tmax ~ tmin + prcp, data = .x)),
    glance = map(model, glance),
    tidy = map(model, tidy)
  )

# r^2
boot_r2 <- boot_results %>%
  unnest(glance) %>%
  select(strap_id, r.squared)

# beta1 / beta2
boot_beta_ratio <- boot_results %>%
  unnest(tidy) %>%
  select(strap_id, term, estimate) %>%
  filter(term %in% c("tmin", "prcp")) %>%
  pivot_wider(names_from = term, values_from = estimate) %>%
  mutate(beta_ratio = tmin / prcp) %>%
  select(strap_id, beta_ratio)

boot_summary <- boot_r2 %>%
  inner_join(boot_beta_ratio, by = "strap_id")

boot_summary
```

### Distribution and 95% Bootstrap CIs

```{r fig.width = 10, fig.height = 4}
# r^2 distribution
p_r2 <- boot_summary %>%
  ggplot(aes(x = r.squared)) +
  geom_histogram(bins = 40, fill = "#0057A8", alpha = 0.7) +
  labs(
    title = "Bootstrap distribution of R-squared",
    x = expression(hat(r)^2),
    y = "Count"
  )

# beta-ratio distribution
p_ratio <- boot_summary %>%
  ggplot(aes(x = beta_ratio)) +
  geom_histogram(bins = 40, fill = "#E53935", alpha = 0.7) +
  labs(
    title = "Bootstrap distribution of beta1 / beta2",
    x = expression(hat(beta)[1] / hat(beta)[2]),
    y = "Count"
  )

p_r2
p_ratio
```

### Comment
1. Bootstrap distribution of $R^2$: the model fits very consistently well, with minimal sampling variability in $R^2$
    - The model explains about 94% of the variance in the response variable across bootstrap samples
    - The tight distribution indicates the model's explanatory power is very stable
    - Even if we refit the model on many resampled datasets, the $R^2$ would remain almost unchanged
    
2. Bootstrap distribution of $\frac{\beta_1}{\beta_2}$: the ratio is much less stable than $R^2$, showing that estimating the relative strength of the two predictors is much less stable than estimating the overall model fit
    - The ratio is consistently negative, meaning the two coefficients have opposite signs in essentially every bootstrap sample
    - The skewness suggests higher variability in one or both coefficients
    - The wide range of values indicates that $\beta_2$ may sometimes be small in magnitude, which creates instability in the ratio
    
```{r}
# 95% bootstrap intervals
r2_ci <- boot_summary %>%
  summarise(
    q2.5  = quantile(r.squared, 0.025),
    q97.5 = quantile(r.squared, 0.975)
  )

ratio_ci <- boot_summary %>%
  summarise(
    q2.5  = quantile(beta_ratio, 0.025),
    q97.5 = quantile(beta_ratio, 0.975)
  )

r2_ci
ratio_ci

```

## Problem 3

```{r}
birth_raw <- read_csv("./data/birthweight.csv")
```

```{r}
birth_df <- birth_raw %>%
  mutate(
    babysex = factor(babysex, levels = c(1, 2),
                     labels = c("male", "female")),
    frace   = factor(frace),
    mrace   = factor(mrace),
    malform = factor(malform, levels = c(0, 1),
                     labels = c("absent", "present"))
  ) %>%
  # drop rows with missing values
  drop_na()
```

### Proposed Regression Model for Birthweight

Here I choose a reasonably rich model using clinical/biological predictors:

- Baby's head circumference and length (`bhead`, `blength`)
- Gestational age in weeks (`gaweeks`)
- Baby sex (`babysex`)
- Mother's pre-pregnancy BMI and weight gain (`ppbmi`, `wtgain`)
- Smoking during pregnancy (`smoken`)

```{r}
mod_main <- lm(
  bwt ~ babysex + bhead + blength + gaweeks +
    ppbmi + wtgain + smoken,
  data = birth_df
)

summary(mod_main)
```

### Residuals vs fitted values
```{r fig.width = 7, fig.height = 5}
birth_aug <- birth_df %>%
  add_predictions(mod_main) %>%
  add_residuals(mod_main)

birth_aug %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.4) +
  geom_hline(yintercept = 0, linetype = 2) +
  labs(
    title = "Residuals vs fitted values: main birthweight model",
    x = "Fitted birthweight",
    y = "Residuals"
  )

```

**Comment**

1. Residual spread increases with fitted birthweight, suggesting heteroscedasticity
2. The residuals are centered around zero, indicating that the model does not show obvious large-scale bias in prediction across the range of fitted values
3. Presence of extreme outliers, which likely correspond to biological or measurement anomalies and may strongly influence the fit

### Comparison Models

1. **Model 1**: length at birth + gestational age
2. **Model 2**: head circumference, length, sex, and all interactions

```{r}
mod1 <- lm(bwt ~ blength + gaweeks, data = birth_df)

mod2 <- lm(
  bwt ~ bhead * blength * babysex,
  data = birth_df
)
```

### Cross-validated Prediction Error

```{r}
set.seed(2025)

cv_df <- crossv_mc(birth_df, n = 100)

cv_results <- cv_df %>%
  mutate(
    train = map(train, as_tibble),
    test  = map(test, as_tibble),

    fit_main = map(train, ~ lm(
      bwt ~ babysex + bhead + blength + gaweeks +
        ppbmi + wtgain + smoken,
      data = .x
    )),
    fit_mod1 = map(train, ~ lm(
      bwt ~ blength + gaweeks,
      data = .x
    )),
    fit_mod2 = map(train, ~ lm(
      bwt ~ bhead * blength * babysex,
      data = .x
    )),

    rmse_main = map2_dbl(fit_main, test, ~ {
      pred  <- predict(.x, newdata = .y)
      sqrt(mean((.y$bwt - pred)^2))
    }),
    rmse_mod1 = map2_dbl(fit_mod1, test, ~ {
      pred  <- predict(.x, newdata = .y)
      sqrt(mean((.y$bwt - pred)^2))
    }),
    rmse_mod2 = map2_dbl(fit_mod2, test, ~ {
      pred  <- predict(.x, newdata = .y)
      sqrt(mean((.y$bwt - pred)^2))
    })
  )

# Summarize and compare
cv_long <- cv_results %>%
  select(rmse_main, rmse_mod1, rmse_mod2) %>%
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse"
  ) %>%
  mutate(
    model = recode(
      model,
      rmse_main = "Main model",
      rmse_mod1 = "Model 1",
      rmse_mod2 = "Model 2"
    )
  )

cv_long %>%
  group_by(model) %>%
  summarise(
    mean_rmse = mean(rmse),
    sd_rmse   = sd(rmse),
    .groups = "drop"
  )
```

```{r fig.width = 10, fig.height = 5}
cv_long %>%
  ggplot(aes(x = model, y = rmse)) +
  geom_boxplot() +
  labs(
    title = "Cross-validated RMSE for birthweight models",
    x = NULL,
    y = "RMSE on test sets"
  ) +
  coord_flip()
```

**Comment**

1. The main model performs best. The median RMSE for the main model is the lowest among the three, and its RMSE distribution is also tight, suggesting stable performance across folds. This indicates that including multiple predictors improves predictive accuracy.
2. Model 2 performs similarly to the main model, and its variability is also modest, suggesting that the three-way interaction contributes useful information, but not enoughg to outperform the main model
3. Model 1 performs the worst and has a much higher median RMSE and the widest spread, suggesting thaht using only two predictors results in substantial information loss